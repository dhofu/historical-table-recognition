{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a page classifier for finding tables in digitized books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how a page classifier was trained for finding tables in digitized books from the collections of the Bavarian State Library. <br>\n",
    "So far, the classifier is rather simple. It is set up to train a Convolutional Neural Network (CNN) for image classification, that distinguishes between 4 classes (Table, TextAndTable, Text, Title). The goal of the page classifier is to quickly find full-page tables across a broad selection of digitized books published between 1750 and 1900.<br>\n",
    "Although the results are satisfactory, there is much scope for improving the page classifier. <br>\n",
    "Additional training data and revision of parameters for training could probably improve the model's performance.<br>\n",
    "Eventually it could be developed into a general classifier that distinguishes between title pages, indices, table of contents, text, pages containing full-page images etc. This, however, is beyond the scope of the current project. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the directory that contains the training data\n",
    "train_data_dir = SELECT_TRAINING_DATA_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image format and set input shape accordingly\n",
    "# This part is to check the data format i.e the RGB channel is coming first or last. \n",
    "# Whatever it may be, the model will check first and then input shape will be fed accordingly.\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\tinput_shape = (3, img_width, img_height)\n",
    "else:\n",
    "\tinput_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 8 # can be reduced to 16 if memory is an issue\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape), \n",
    "    \n",
    "    # First Convolutional Block\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax') # number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer with customized parameters\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, # for second model, learning rate is reduced to 0.0002\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "# Compile model with additional metrics\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.F1Score(name='f1_score', threshold=0.5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data (similar to rescale=1./255 in ImageDataGenerator)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Apply normalization to the datasets\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Optimize the datasets for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint('best_model_v2.keras', save_best_only=True, monitor='val_accuracy'), # saves best model during training\n",
    "    EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save('final_model.keras') # it is possible to save only the weights using model.save_weights('model_weights.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
